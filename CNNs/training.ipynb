{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhl1bSsBjexg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# transform the images to a tensor and normalize it so that the mean is 0.5 (so the data is centered at 0 :[-0.5 to 0.5]. And Std. dev. is 0.5 which means the range is [-1, 1])\n",
    "data_transform = torchvision.transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#download the CIFAR10 dataset. Further split the train set to train and test sets.\n",
    "train_set = torchvision.datasets.CIFAR10(root = '/content/drive/MyDrive/DL_review/CNNs', train=True, download=True, transform=data_transform)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [int(len(train_set)*0.8), int(len(train_set)*0.2)])\n",
    "test_set = torchvision.datasets.CIFAR10(root = '/content/drive/MyDrive/DL_review/CNNs', train=False, download=True, transform=data_transform)\n",
    "\n",
    "# This is how you would load the data if it is from a local directory with structure (data/train/class1/img1.jpg)\n",
    "# train_set = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/DL_review/CNNs/dataset', transform=data_transform)\n",
    "\n",
    "#load the downloaded data with a batch size. set shuffle=True for the train set.\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wYo6mAjjsIM",
    "outputId": "3fca760d-d901-46a8-bfc7-079ce5d0af38"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cjwnZkLCzkaJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "id": "6U1Rh5Ca0uQk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's build a custom CNN for training. This CNN is similar to VGG16. It uses only 3 X 3 filters and has max_pooling layer after every block.\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomCNN, self).__init__()\n",
    "\n",
    "\n",
    "    self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(num_features=64)\n",
    "    self.relu_1 = nn.ReLU()\n",
    "    self.conv_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "    self.relu_2 = nn.ReLU()\n",
    "    self.max_pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "    self.conv_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3 = nn.BatchNorm2d(num_features=128)\n",
    "    self.relu_3 = nn.ReLU()\n",
    "    self.conv_4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4 = nn.BatchNorm2d(num_features=128)\n",
    "    self.relu_4 = nn.ReLU()\n",
    "    self.max_pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.conv_5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "    self.relu_5 = nn.ReLU()\n",
    "    self.conv_6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "    self.relu_6 = nn.ReLU()\n",
    "    self.max_pool_3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(4 * 4* 256, 512)\n",
    "    self.relu_fc1 = nn.ReLU()\n",
    "\n",
    "    self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.max_pool_1(self.relu_2(self.bn2(self.conv_2(self.relu_1(self.bn1(self.conv_1(x)))))))\n",
    "\n",
    "    x = self.max_pool_2(self.relu_4(self.bn4(self.conv_4(self.relu_3(self.bn3(self.conv_3(x)))))))\n",
    "\n",
    "    # print(x)\n",
    "\n",
    "    x = self.max_pool_3(self.relu_6(self.conv_6(self.relu_5(self.conv_5(x)))))\n",
    "\n",
    "    x = torch.flatten(x,1)\n",
    "\n",
    "    x = self.relu_fc1(self.fc1(x))\n",
    "\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x\n",
    "\n"
   ],
   "metadata": {
    "id": "M6uCMLoqorm4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def init_weights(m):\n",
    "  if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "    nn.init.kaiming_normal_(m.weight, nonlinearity='relu') #Initialization of weights with He\n",
    "    if m.bias is not None:\n",
    "      nn.init.constant(m.bias, 0)"
   ],
   "metadata": {
    "id": "Y-IPDTji4Ytk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Checking if everything is right. Took an image data from the train set and ran it through the model.\n",
    "# Unsqueezing as the model expects a batch of inputs. The output shape is as expected.\n",
    "\n",
    "cnn = CustomCNN()\n",
    "\n",
    "cnn.apply(init_weights)\n",
    "\n",
    "# data = train_set.dataset[0][0].unsqueeze(0)\n",
    "\n",
    "# print(cnn(data).shape)"
   ],
   "metadata": {
    "id": "CVhSBWFfvNhN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "03d49a22-47e9-48f2-d624-fb3ddfd0913d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-21-0b9340733bf2>:5: FutureWarning: `nn.init.constant` is now deprecated in favor of `nn.init.constant_`.\n",
      "  nn.init.constant(m.bias, 0)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_2): ReLU()\n",
       "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3): ReLU()\n",
       "  (conv_4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_4): ReLU()\n",
       "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_5): ReLU()\n",
       "  (conv_6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_6): ReLU()\n",
       "  (max_pool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (relu_fc1): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Loss Function and Optimizer\n",
    "\n",
    "We will be using CrossEntropy loss as we are dealing with classification. You should have noticed that we didn't add a Softmax layer to the model That is because the nn.CrossEntropyLoss function applies the Softmax function."
   ],
   "metadata": {
    "id": "6nIDWxa85_UQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)"
   ],
   "metadata": {
    "id": "blnezVrk3t8g"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oM79o25N68rw",
    "outputId": "e379a1f4-e4f5-4d17-93c4-0ec948a44694"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Dictionary to store zero activation percentages\n",
    "activation_stats = {}\n",
    "\n",
    "# Hook function to track activations\n",
    "def activation_hook(module, input, output):\n",
    "    zero_activations = (output == 0).float().sum().item()\n",
    "    total_activations = output.numel()\n",
    "    percentage_zeros = 100 * (zero_activations / total_activations)\n",
    "\n",
    "    activation_stats[module] = percentage_zeros\n",
    "\n",
    "    print(f\"{module}: {percentage_zeros:.2f}% of activations are zero.\")\n",
    "\n",
    "# Register hooks for all ReLU layers\n",
    "for name, module in cnn.named_modules():\n",
    "    if isinstance(module, nn.ReLU):\n",
    "        module.register_forward_hook(activation_hook)\n",
    "\n",
    "# Run a sample batch through the model\n",
    "cnn.to(device)\n",
    "images, _ = next(iter(train_loader))  # Get one batch\n",
    "images = images.to(device)\n",
    "\n",
    "# Forward pass to collect activation stats\n",
    "# with torch.no_grad():\n",
    "cnn(images)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBxcjHC28vgd",
    "outputId": "53c6ec6a-b7c1-4768-b7f0-a74787e808c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ReLU(): 49.75% of activations are zero.\n",
      "ReLU(): 50.14% of activations are zero.\n",
      "ReLU(): 49.60% of activations are zero.\n",
      "ReLU(): 50.19% of activations are zero.\n",
      "ReLU(): 49.25% of activations are zero.\n",
      "ReLU(): 50.01% of activations are zero.\n",
      "ReLU(): 53.45% of activations are zero.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-7.8741e-01, -1.4695e+00, -2.2932e+00, -2.2524e+00, -7.0744e-01,\n",
       "          2.2715e+00,  5.9934e-01, -8.8993e-01,  1.6695e+00, -6.8386e-02],\n",
       "        [-2.4575e+00, -1.5489e+00, -3.3655e-01, -1.9399e+00, -1.8773e-01,\n",
       "          1.1105e+00,  1.1105e+00, -9.5691e-01,  2.4761e-01,  1.1870e+00],\n",
       "        [-4.9822e-01, -1.2594e+00, -6.4023e-01, -1.4078e+00, -6.3174e-01,\n",
       "          1.6941e+00,  6.5590e-01, -1.1169e+00,  1.8179e+00, -4.5276e-01],\n",
       "        [-1.3631e+00, -1.0368e+00, -1.0750e+00, -2.1930e+00, -1.2486e-01,\n",
       "          2.0455e+00,  1.9853e+00, -4.7206e-01,  1.5076e+00,  2.9280e-03],\n",
       "        [-1.3576e+00, -8.1563e-01, -2.6726e+00, -2.4300e+00,  7.1973e-01,\n",
       "          1.9257e+00,  4.9036e-01, -1.3794e+00,  2.0626e+00,  3.8015e-02],\n",
       "        [-1.3104e+00, -1.8936e+00, -3.9785e-01, -2.5656e+00, -7.7043e-01,\n",
       "          2.7915e+00,  8.6541e-01, -1.7169e+00,  1.6483e+00,  6.8361e-01],\n",
       "        [-1.1819e+00, -1.8333e+00, -1.7381e+00, -3.1166e+00,  6.5176e-01,\n",
       "          3.2931e+00,  6.1629e-01, -1.4750e+00,  8.3989e-01, -5.0515e-01],\n",
       "        [-5.0511e-01, -1.0190e+00, -5.3900e-01, -9.3162e-01,  6.8286e-01,\n",
       "          2.0184e+00,  1.3638e+00, -8.1830e-01,  1.3095e+00,  5.7161e-01],\n",
       "        [-9.3777e-01, -3.8712e-01, -1.0935e+00, -7.4180e-01,  2.8954e-01,\n",
       "          1.6251e+00,  8.4948e-01, -4.0436e-01, -1.0546e-01,  7.6341e-01],\n",
       "        [-1.5854e+00, -7.7707e-01, -3.5097e-01, -8.5938e-01, -6.8632e-02,\n",
       "          2.3308e+00,  3.9336e-01, -1.1372e+00,  3.5442e-01, -1.7006e-01],\n",
       "        [-1.6613e+00, -1.2444e+00, -2.3595e+00, -3.4697e+00, -3.3508e-02,\n",
       "          3.4074e+00,  1.2939e+00,  5.4638e-01,  1.7180e+00,  1.0301e+00],\n",
       "        [-7.3284e-01, -3.5273e-01, -8.0971e-01, -8.8946e-01, -3.0719e-01,\n",
       "          8.3146e-01,  7.3180e-01, -4.1133e-01,  1.3569e+00,  1.0143e+00],\n",
       "        [-1.9124e+00, -2.1540e+00, -1.5891e+00, -2.6392e+00, -1.5007e+00,\n",
       "          2.9161e+00, -3.0735e-01, -1.2248e+00,  1.2598e+00, -1.4294e-02],\n",
       "        [-5.4675e-01, -2.2367e+00, -1.7981e+00, -3.1854e+00,  5.2724e-01,\n",
       "          2.7392e+00,  1.2078e+00, -1.3012e+00,  1.5428e+00,  2.6142e-01],\n",
       "        [-1.0292e+00, -1.2484e+00, -4.8954e-01, -1.7260e+00, -1.2448e+00,\n",
       "          1.1194e-01,  7.8000e-02, -5.1338e-01, -2.5387e-01,  6.0401e-01],\n",
       "        [-1.7102e+00, -8.2064e-01, -1.6062e+00, -3.4262e+00, -1.1014e+00,\n",
       "          1.5392e+00,  1.9090e+00, -8.8627e-01,  3.3108e-01,  3.7712e-01],\n",
       "        [-9.7751e-01, -3.8504e+00, -4.1880e-01, -1.4724e+00,  7.6478e-01,\n",
       "          2.9466e+00,  2.0257e+00,  5.7455e-01,  2.7582e+00,  1.1327e+00],\n",
       "        [-1.1396e+00, -1.2974e+00, -1.2590e+00, -2.8970e+00,  3.9160e-01,\n",
       "          3.0839e+00,  4.9846e-01, -2.0455e+00,  7.8624e-01,  7.0590e-01],\n",
       "        [-1.4681e+00, -8.8385e-01, -1.7935e+00, -3.1648e+00, -4.5521e-02,\n",
       "          1.4788e+00,  2.6622e-01, -1.1276e+00,  1.3657e+00,  4.4201e-01],\n",
       "        [-1.1830e+00, -1.3770e+00, -1.9825e+00, -3.7078e+00,  1.5049e-01,\n",
       "          5.2346e+00,  1.8376e+00, -1.3658e+00,  1.7332e+00,  5.2128e-02],\n",
       "        [-1.3548e+00, -1.9758e+00, -1.3686e+00, -2.9129e+00, -1.8548e-01,\n",
       "          1.3284e+00,  1.7259e+00, -5.8084e-01,  1.6264e+00,  8.9593e-01],\n",
       "        [-7.9676e-01, -1.9908e+00, -7.5297e-01, -2.3055e+00, -6.4429e-01,\n",
       "          1.8451e+00,  1.2971e+00, -2.5440e-01,  8.7204e-01, -4.2863e-02],\n",
       "        [-1.5709e+00, -8.6380e-01, -6.9763e-01, -1.1312e+00,  4.1694e-01,\n",
       "          1.9591e+00,  3.3176e-01, -7.3797e-01,  1.4839e+00, -1.0743e+00],\n",
       "        [-9.6648e-01, -2.5120e+00, -1.2778e+00, -3.4650e+00, -9.4951e-01,\n",
       "          6.4049e-01,  1.3357e+00, -1.4409e-01,  1.6983e+00,  1.0908e+00],\n",
       "        [-1.9862e+00, -1.0111e+00, -4.2992e-01, -3.3995e+00,  1.4147e-01,\n",
       "          2.1932e+00,  3.8431e-01, -1.1261e+00,  1.2430e+00,  1.0759e+00],\n",
       "        [-1.0813e+00, -1.0261e+00, -1.4766e+00, -1.3864e+00, -3.1716e-01,\n",
       "          2.1896e+00,  5.5874e-01, -3.7840e-01,  1.8413e+00,  4.6958e-01],\n",
       "        [-8.1388e-01, -5.7840e-01, -1.4934e+00, -2.5398e+00, -8.2813e-01,\n",
       "          2.5277e+00,  1.2651e+00, -1.5564e+00,  1.1544e+00,  5.4469e-01],\n",
       "        [ 2.4624e-01, -5.2255e-01, -3.5054e-01, -2.4417e+00, -1.1817e+00,\n",
       "          1.2625e+00,  1.0193e+00, -1.0221e+00,  8.3188e-01,  2.3251e-01],\n",
       "        [-1.4767e+00, -9.3370e-01, -7.5125e-01, -1.9902e+00, -4.8561e-01,\n",
       "          5.4869e-02,  1.2406e+00, -4.1570e-01,  5.7701e-01,  4.2182e-01],\n",
       "        [-9.8279e-01, -2.3558e+00, -1.9057e+00, -4.0975e+00, -9.2821e-01,\n",
       "          2.5207e+00,  2.2033e-01, -1.8364e+00,  1.0645e+00,  8.6714e-01],\n",
       "        [-7.4793e-01, -2.0673e+00, -1.1447e+00, -2.1028e+00, -7.2598e-02,\n",
       "          2.0201e+00,  7.6493e-01, -2.0720e+00,  1.4293e+00, -2.8629e-01],\n",
       "        [-8.0209e-01, -8.6192e-01, -1.4824e+00, -3.5419e+00, -4.3582e-01,\n",
       "          3.7245e+00,  1.9031e+00, -2.0126e+00,  7.2852e-01,  3.6911e-01],\n",
       "        [-1.1922e+00, -6.5172e-01, -8.8525e-01, -2.8731e+00,  1.4227e-01,\n",
       "          3.1732e+00,  1.6133e+00, -1.7094e+00,  1.1065e+00,  4.0161e-02],\n",
       "        [-7.5843e-01, -1.1868e+00, -3.5844e-01, -1.8683e+00,  4.1356e-01,\n",
       "          1.9758e+00,  1.2375e+00, -2.1628e+00,  1.4929e+00,  1.8044e-01],\n",
       "        [-3.3139e-02, -1.0516e+00, -1.7643e+00, -1.2160e+00, -9.7700e-01,\n",
       "          8.3339e-01,  7.5791e-01, -1.0984e+00,  9.2050e-01,  3.3126e-01],\n",
       "        [-1.0819e+00, -1.1311e+00, -9.9609e-01, -1.8926e+00,  2.2538e-01,\n",
       "          2.8731e+00,  1.1334e+00, -1.6298e+00,  2.1236e+00,  4.8648e-02],\n",
       "        [-4.2290e-01, -1.0347e+00, -2.0535e+00, -2.7771e+00, -1.8030e-01,\n",
       "          2.7585e+00,  9.2568e-02, -1.3493e+00,  3.2872e-01, -9.0813e-01],\n",
       "        [-1.3445e+00, -2.3125e+00, -2.9402e+00, -3.9323e+00, -1.0572e+00,\n",
       "          4.2377e+00,  9.9865e-01, -1.7687e+00,  3.1546e+00,  1.4065e+00],\n",
       "        [-1.1648e+00, -1.2179e+00, -2.5408e+00, -2.2388e+00,  5.9431e-01,\n",
       "          1.6614e+00,  1.1721e+00,  2.2366e-01,  1.9661e+00,  7.1968e-01],\n",
       "        [-1.1486e+00, -1.5955e+00, -1.5556e+00, -2.3225e+00, -7.3431e-01,\n",
       "          3.2314e+00,  2.1020e+00, -1.2093e+00,  9.6114e-01,  7.0091e-01],\n",
       "        [-1.2911e+00, -2.2649e+00,  2.6846e-02, -4.5779e+00, -1.7990e+00,\n",
       "          3.8030e+00,  2.6234e+00, -3.0553e+00,  2.0431e+00,  1.8009e+00],\n",
       "        [-2.3292e+00, -1.1254e+00, -3.4864e+00, -7.1850e+00,  1.0112e-01,\n",
       "          2.5971e+00,  7.3358e-01, -1.3694e+00,  2.4192e+00,  8.1870e-01],\n",
       "        [-2.9140e-01, -7.7741e-01, -1.0398e+00, -2.1542e+00, -3.2933e-01,\n",
       "          2.7131e+00, -4.0538e-02, -1.0352e+00,  6.1994e-01, -3.9754e-01],\n",
       "        [-1.7747e+00, -1.5392e+00,  2.9987e-01, -1.8256e+00,  3.7180e-01,\n",
       "          2.0303e+00, -1.0925e+00, -8.6694e-01,  8.9136e-01,  5.6854e-01],\n",
       "        [-1.6076e+00, -1.5422e-01, -2.5794e-01, -1.2007e+00, -2.4351e-01,\n",
       "          1.6367e+00,  9.0824e-01, -8.7966e-01,  8.0039e-01,  2.2336e-01],\n",
       "        [-1.0798e+00, -1.7586e-01, -7.1753e-01, -1.8827e+00,  3.6403e-01,\n",
       "          3.5680e+00,  1.3262e-01, -1.1480e+00,  1.3500e+00,  5.2202e-01],\n",
       "        [-9.6342e-01, -1.1578e+00, -1.2194e+00, -3.2452e+00, -7.5411e-01,\n",
       "          1.9965e+00,  1.0299e+00, -1.6989e+00,  6.8832e-01, -5.0260e-01],\n",
       "        [-1.6747e+00, -1.1878e+00, -1.1103e+00, -2.4752e+00, -6.5626e-01,\n",
       "          3.0388e+00,  5.6584e-01, -2.1191e+00,  2.2411e+00,  7.6660e-01],\n",
       "        [-1.5839e+00, -6.5634e-01, -7.9750e-01, -1.8974e+00, -6.4965e-01,\n",
       "          8.6349e-01,  1.1630e+00, -7.1392e-01,  5.2534e-01,  1.4644e+00],\n",
       "        [-2.2615e+00, -1.7358e+00, -1.2026e+00, -3.7917e+00,  6.6042e-04,\n",
       "          1.5885e+00,  2.0506e+00, -1.9594e-01,  9.2821e-01,  1.1620e+00],\n",
       "        [-4.8467e-01, -6.3916e-01, -1.0422e+00, -1.1487e+00, -4.6912e-01,\n",
       "          1.5171e+00,  2.4893e-01, -1.2740e+00,  5.4212e-01, -6.6429e-01],\n",
       "        [-8.8911e-01, -1.6384e+00, -1.1310e+00, -2.4074e+00, -1.6278e+00,\n",
       "          1.2519e+00,  1.6724e+00, -2.1551e+00,  2.2770e+00,  6.2684e-01],\n",
       "        [-1.0028e+00, -1.5184e+00, -1.5519e-01, -2.5612e+00, -1.2937e+00,\n",
       "          7.8286e-01,  4.9588e-01, -6.4609e-01,  9.3169e-01,  6.5100e-01],\n",
       "        [-8.2170e-01,  1.3609e-01, -1.1210e+00, -1.3327e+00,  5.0718e-01,\n",
       "          1.9349e+00,  7.8775e-01, -1.7638e+00,  2.2200e+00,  5.6571e-01],\n",
       "        [-3.5742e-01, -5.9201e-01, -1.3361e+00, -1.6192e+00, -2.5656e-01,\n",
       "          2.0533e+00,  5.5038e-01, -7.8405e-01,  1.4981e+00, -9.1590e-02],\n",
       "        [-4.7613e-01, -2.0501e+00, -5.8664e-01, -2.2714e+00,  6.4212e-02,\n",
       "          1.4544e+00,  1.7056e+00, -6.5990e-01,  2.3811e+00,  5.5263e-01],\n",
       "        [-6.6765e-01, -1.9242e-02, -6.2740e-01, -1.8020e+00,  2.5708e-01,\n",
       "          1.5855e+00, -6.0937e-02, -1.4605e+00,  1.0362e+00,  7.3710e-01],\n",
       "        [-6.6321e-01, -1.1650e+00, -1.9212e+00, -1.8173e+00, -8.4569e-01,\n",
       "          1.2207e+00,  2.1903e-02, -1.2931e+00,  6.7972e-01, -6.6239e-03],\n",
       "        [-1.0979e+00,  4.2742e-02, -1.8388e+00, -1.3609e+00,  3.9702e-01,\n",
       "          6.1976e-01,  7.3593e-01,  1.0078e-01,  2.2226e+00,  2.1866e-01],\n",
       "        [ 8.8566e-02, -2.6925e+00, -2.4261e+00, -1.8610e+00, -1.3987e+00,\n",
       "          1.7430e+00,  1.3800e+00, -2.1225e-01,  1.8686e+00, -5.0748e-01],\n",
       "        [-1.8828e+00, -2.2448e+00, -6.6182e-01, -3.5983e+00, -1.3937e-01,\n",
       "          2.2929e+00,  3.8361e-01, -1.7485e+00,  1.7487e+00, -3.5711e-02],\n",
       "        [-1.1616e+00, -6.7548e-01, -7.7867e-01, -3.0250e+00,  4.0685e-01,\n",
       "          1.6225e+00, -5.9480e-01, -1.2092e+00,  1.7210e+00, -4.2780e-02],\n",
       "        [-1.5606e+00, -2.0320e-01, -1.0165e+00, -3.0197e+00, -3.1068e-01,\n",
       "          2.0128e+00,  7.5222e-01, -7.5925e-01,  2.2029e+00,  1.0028e+00],\n",
       "        [-1.2181e+00, -1.7684e+00, -4.9656e-01, -1.7222e+00, -2.3556e-01,\n",
       "          1.1978e+00,  8.8353e-01, -1.9046e+00,  9.4429e-01, -2.9363e-01]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  cnn.to(device)\n",
    "  cnn.train()\n",
    "  running_loss = 0.0\n",
    "\n",
    "  for images, labels in train_loader:\n",
    "\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds = cnn(images)\n",
    "\n",
    "    batch_loss = criterion(preds, labels)\n",
    "\n",
    "    batch_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += batch_loss.item()\n",
    "\n",
    "  cnn.eval()\n",
    "  running_val_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      preds = cnn(images)\n",
    "\n",
    "      batch_val_loss = criterion(preds, labels)\n",
    "\n",
    "      running_val_loss += batch_val_loss.item()\n",
    "\n",
    "  print(f'Epoch {epoch+1} completed. loss: {running_loss/len(train_loader)}, validation loss : {running_val_loss/len(val_loader)}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "VCOZb5Iz6CN0"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
